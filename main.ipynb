{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "from PIL import Image\n",
    "from PIL import ImageFilter as Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edge_enhancing(array):\n",
    "    method = np.random.choice(['ada_thold', 'laplacian', 'edge_enahnced'])\n",
    "    \n",
    "    if method=='ada_thold':     \n",
    "        return np.expand_dims(cv2.adaptiveThreshold(array, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, 1), 2)\n",
    "    \n",
    "    elif method=='laplacian':\n",
    "        return np.expand_dims(cv2.Laplacian(array,cv2.CV_64F, ksize=5), 2)\n",
    "    \n",
    "    else:\n",
    "        image = Image.fromarray(np.squeeze(array, axis=2)).convert('L')\n",
    "        return np.expand_dims(np.asarray(image.filter(Filter.EDGE_ENHANCE_MORE)), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def de_texturization(array):\n",
    "    n = np.random.choice([5, 9, 13, 15])\n",
    "    sigma = np.random.choice([50, 65, 75])\n",
    "    \n",
    "    return np.expand_dims(cv2.bilateralFilter(array, n, sigma, sigma), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_flip(array):    \n",
    "    if random.choice([True, False]):\n",
    "        return tf.image.random_flip_left_right(array).numpy()\n",
    "    else:\n",
    "        return tf.image.random_flip_up_down(array).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tumbnail(array, shape=(512,512)):\n",
    "    return cv2.resize(array, shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_crop(array):\n",
    "    method = np.random.choice(['left', 'right', 'top', 'down'])\n",
    "    v_center = array.shape[1]//2\n",
    "    h_center = array.shape[0]//2\n",
    "    \n",
    "    if method == 'left':\n",
    "        return array[:,:v_center,:]\n",
    "    elif method == 'right':\n",
    "        return array[:,v_center:,:]\n",
    "    elif method == 'top':\n",
    "        return array[:h_center,:,:]\n",
    "    elif method == 'down':\n",
    "        return array[h_center:,:,:]\n",
    "    else:\n",
    "        return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_procrssing(image):\n",
    "    temp = np.asarray(image)\n",
    "    \n",
    "    if np.random.choice([True, False], p=[0.45, 0.55]):\n",
    "        # other augmentaions\n",
    "        temp = de_texturization(temp)\n",
    "        \n",
    "        # crop\n",
    "        if random.choice([True, False]):\n",
    "            temp = tf.image.random_crop(temp, (128,128,1)).numpy()\n",
    "        else:\n",
    "            temp = random_crop(temp)\n",
    "        \n",
    "        temp = tumbnail(temp, (input_size, input_size))\n",
    "\n",
    "        return np.expand_dims(temp, 2)\n",
    "    \n",
    "    else:\n",
    "        return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>image_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>./images/train/1.2.826.0.1.3680043.8.498.10025...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "      <td>./images/train/1.2.826.0.1.3680043.8.498.10036...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>./images/train/1.2.826.0.1.3680043.8.498.10038...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>./images/train/1.2.826.0.1.3680043.8.498.10050...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>./images/train/1.2.826.0.1.3680043.8.498.10053...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1733</th>\n",
       "      <td>14</td>\n",
       "      <td>./images/train/1.2.826.0.1.3680043.8.498.99711...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1734</th>\n",
       "      <td>11</td>\n",
       "      <td>./images/train/1.2.826.0.1.3680043.8.498.99727...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1735</th>\n",
       "      <td>3</td>\n",
       "      <td>./images/train/1.2.826.0.1.3680043.8.498.99935...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1736</th>\n",
       "      <td>2</td>\n",
       "      <td>./images/train/1.2.826.0.1.3680043.8.498.99969...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1737</th>\n",
       "      <td>2</td>\n",
       "      <td>./images/train/1.2.826.0.1.3680043.8.498.99979...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1738 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Target                                         image_path\n",
       "0        0   ./images/train/1.2.826.0.1.3680043.8.498.10025...\n",
       "1       15   ./images/train/1.2.826.0.1.3680043.8.498.10036...\n",
       "2       12   ./images/train/1.2.826.0.1.3680043.8.498.10038...\n",
       "3       14   ./images/train/1.2.826.0.1.3680043.8.498.10050...\n",
       "4        3   ./images/train/1.2.826.0.1.3680043.8.498.10053...\n",
       "...     ...                                                ...\n",
       "1733    14   ./images/train/1.2.826.0.1.3680043.8.498.99711...\n",
       "1734    11   ./images/train/1.2.826.0.1.3680043.8.498.99727...\n",
       "1735     3   ./images/train/1.2.826.0.1.3680043.8.498.99935...\n",
       "1736     2   ./images/train/1.2.826.0.1.3680043.8.498.99969...\n",
       "1737     2   ./images/train/1.2.826.0.1.3680043.8.498.99979...\n",
       "\n",
       "[1738 rows x 2 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('data/train_df.csv', usecols=['image_path', 'Target'])\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>image_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>data/data/images/train/1.2.826.0.1.3680043.8.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "      <td>data/data/images/train/1.2.826.0.1.3680043.8.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>data/data/images/train/1.2.826.0.1.3680043.8.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>data/data/images/train/1.2.826.0.1.3680043.8.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>data/data/images/train/1.2.826.0.1.3680043.8.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1733</th>\n",
       "      <td>10</td>\n",
       "      <td>data/data/images/train/1.2.826.0.1.3680043.8.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1734</th>\n",
       "      <td>13</td>\n",
       "      <td>data/data/images/train/1.2.826.0.1.3680043.8.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1735</th>\n",
       "      <td>13</td>\n",
       "      <td>data/data/images/train/1.2.826.0.1.3680043.8.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1736</th>\n",
       "      <td>0</td>\n",
       "      <td>data/data/images/train/1.2.826.0.1.3680043.8.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1737</th>\n",
       "      <td>13</td>\n",
       "      <td>data/data/images/train/1.2.826.0.1.3680043.8.4...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1738 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Target                                         image_path\n",
       "0         0  data/data/images/train/1.2.826.0.1.3680043.8.4...\n",
       "1        15  data/data/images/train/1.2.826.0.1.3680043.8.4...\n",
       "2        12  data/data/images/train/1.2.826.0.1.3680043.8.4...\n",
       "3        14  data/data/images/train/1.2.826.0.1.3680043.8.4...\n",
       "4         3  data/data/images/train/1.2.826.0.1.3680043.8.4...\n",
       "...     ...                                                ...\n",
       "1733     10  data/data/images/train/1.2.826.0.1.3680043.8.4...\n",
       "1734     13  data/data/images/train/1.2.826.0.1.3680043.8.4...\n",
       "1735     13  data/data/images/train/1.2.826.0.1.3680043.8.4...\n",
       "1736      0  data/data/images/train/1.2.826.0.1.3680043.8.4...\n",
       "1737     13  data/data/images/train/1.2.826.0.1.3680043.8.4...\n",
       "\n",
       "[1738 rows x 2 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['Target'] = train_df['Target'].str.strip()\n",
    "train_df['image_path'] = train_df['image_path'].apply(lambda x: os.path.join(\"data\", x.lstrip(\"./\")))\n",
    "train_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1390, 2), (348, 2))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "split_data = train_df[['image_path', 'Target']]\n",
    "train, test = train_test_split(train_df[['image_path', 'Target']], test_size=0.2)\n",
    "train.shape, test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XrayDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            dataframe (pd.DataFrame): DataFrame with columns \"Target\" and \"image_path\".\n",
    "            transform (callable, optional): Transform to be applied on an image.\n",
    "        \"\"\"\n",
    "        self.df = dataframe\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_path = row[\"image_path\"]\n",
    "        # Convert label to an integer and then to a torch tensor (of type long)\n",
    "        label = torch.tensor(int(row[\"Target\"]), dtype=torch.long)\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "\n",
    "# Define transformations (resize to 224x224 and convert to tensor)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Create the dataset and dataloader\n",
    "train_dataset = XrayDataset(train, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_dataset = XrayDataset(test, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNClassifier(nn.Module):\n",
    "    def __init__(self, num_classes=16):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            num_classes (int): Number of target classes.\n",
    "        \"\"\"\n",
    "        super(CNNClassifier, self).__init__()\n",
    "        # Using padding to keep spatial dimensions, then reducing with pooling.\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        # Adaptive pooling to get a fixed feature size regardless of the input dimensions.\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((7, 7))\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))  # [batch, 32, 112, 112]\n",
    "        x = self.pool(F.relu(self.conv2(x)))  # [batch, 64, 56, 56]\n",
    "        x = self.avgpool(x)                   # [batch, 64, 7, 7]\n",
    "        x = x.view(x.size(0), -1)             # flatten to [batch, 64*7*7]\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)                     # logits output\n",
    "        return x\n",
    "\n",
    "# Determine the device (GPU if available)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# It's a good idea to automatically determine the number of classes.\n",
    "num_classes = train_df[\"Target\"].nunique()  \n",
    "model = CNNClassifier(num_classes=num_classes).to(device)\n",
    "\n",
    "# Step 3: Define Loss Function and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Step 4: Training Loop\n",
    "epochs = 10  # You can adjust the number of epochs as needed\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device)\n",
    "        # Ensure labels are the right type (long) for CrossEntropyLoss.\n",
    "        labels = labels.to(device).long()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {avg_loss:.4f}\")\n",
    "\n",
    "# Optional: Save the trained model\n",
    "torch.save(model.state_dict(), \"xray_model.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# First, accumulate predictions and true labels from the test dataset.\n",
    "true_labels = []\n",
    "pred_labels = []\n",
    "\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        # Ensure labels are tensors and in the correct type\n",
    "        labels = torch.tensor(labels, device=device, dtype=torch.long)\n",
    "        \n",
    "        # Get model predictions\n",
    "        outputs = model(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        \n",
    "        # Save predictions and true labels\n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "        pred_labels.extend(preds.cpu().numpy())\n",
    "\n",
    "# Compute the confusion matrix from the true and predicted labels.\n",
    "conf_metric = confusion_matrix(true_labels, pred_labels)\n",
    "\n",
    "# Normalize the confusion matrix by dividing each row by its sum (i.e., relative percentages).\n",
    "conf_metric_normalized = conf_metric / np.sum(conf_metric, axis=1, keepdims=True)\n",
    "\n",
    "# Plot the confusion matrix using Seaborn.\n",
    "plt.figure(figsize=[12,12], dpi=100)\n",
    "sns.heatmap(np.round(conf_metric_normalized, 2),\n",
    "            cbar=False,\n",
    "            annot=True,\n",
    "            annot_kws={\"size\": 9},\n",
    "            cmap=plt.cm.Blues)\n",
    "plt.xlabel('True labels')\n",
    "plt.ylabel('Predicted labels')\n",
    "plt.title('Normalized Confusion Matrix')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cmpt419_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
